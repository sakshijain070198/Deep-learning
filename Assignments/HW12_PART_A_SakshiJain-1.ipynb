{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4WsAryrw4wU"
      },
      "source": [
        "# Part A: Build a code understanding model. Upload your own custom code files to the model and ask questions based on the code file as context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg8_mMrYw4wV"
      },
      "source": [
        "### Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnRFn2gdw4wV"
      },
      "source": [
        "Before we start building our chatbot, we need to install some Python libraries. Here's a brief overview of what each library does:\n",
        "\n",
        "- **langchain**: This is a library for GenAI. We'll use it to chain together different language models and components for our chatbot.\n",
        "- **openai**: This is the official OpenAI Python client. We'll use it to interact with the OpenAI API and generate responses for our chatbot.\n",
        "- **datasets**: This library provides a vast array of datasets for machine learning. We'll use it to load our knowledge base for the chatbot.\n",
        "- **pinecone-client**: This is the official Pinecone Python client. We'll use it to interact with the Pinecone API and store our chatbot's knowledge base in a vector database.\n",
        "\n",
        "You can install these libraries using pip like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CflZ3e82w4wV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "3f5f56b1-7724-4890-9a93-c7611fef7201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 0.3.11\n",
            "Uninstalling langchain-0.3.11:\n",
            "  Successfully uninstalled langchain-0.3.11\n",
            "Found existing installation: langchain-core 0.3.24\n",
            "Uninstalling langchain-core-0.3.24:\n",
            "  Successfully uninstalled langchain-core-0.3.24\n",
            "Found existing installation: langchain-community 0.0.20\n",
            "Uninstalling langchain-community-0.0.20:\n",
            "  Successfully uninstalled langchain-community-0.0.20\n",
            "Found existing installation: langsmith 0.2.2\n",
            "Uninstalling langsmith-0.2.2:\n",
            "  Successfully uninstalled langsmith-0.2.2\n",
            "Found existing installation: fsspec 2024.9.0\n",
            "Uninstalling fsspec-2024.9.0:\n",
            "  Successfully uninstalled fsspec-2024.9.0\n",
            "Found existing installation: gcsfs 2024.10.0\n",
            "Uninstalling gcsfs-2024.10.0:\n",
            "  Successfully uninstalled gcsfs-2024.10.0\n",
            "/bin/bash: line 1: 0.2: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall langchain langchain-core langchain-community langsmith fsspec gcsfs -y\n",
        "!pip install \\\n",
        "  langchain \\\n",
        "  langchain-community==0.0.20 \\\n",
        "  langchain-core<0.2 \\\n",
        "  langsmith<0.1 \\\n",
        "  fsspec==2024.10.0 \\\n",
        "  gcsfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUH6ontXw4wV"
      },
      "source": [
        "### Building a Chatbot (no RAG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAps57bQw4wW"
      },
      "source": [
        "We will be relying heavily on the LangChain library to bring together the different components needed for our chatbot. To begin, we'll create a simple chatbot without any retrieval augmentation. We do this by initializing a `ChatOpenAI` object. For this we do need an [OpenAI API key](https://platform.openai.com/account/api-keys)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'your_api_key'"
      ],
      "metadata": {
        "id": "cZ9wwnkyqREy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"your_api_key\")\n"
      ],
      "metadata": {
        "id": "UZ5WZz45F8i5"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "kSbM7Phiw4wW"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import (\n",
        "    SystemMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the conversation messages\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hi AI, how are you today?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"I'm great thank you. How can I help you?\"},\n",
        "    {\"role\": \"user\", \"content\": \"I'd like to understand string theory.\"}\n",
        "]"
      ],
      "metadata": {
        "id": "9HY-GZBYTvsO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the first API call to get the assistant's response\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "# Add the latest assistant response to the messages\n",
        "assistant_response = response.choices[0].message.content\n",
        "messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "# Create a new user prompt\n",
        "new_user_prompt = \"Why do physicists believe it can produce a 'unified theory'?\"\n",
        "messages.append({\"role\": \"user\", \"content\": new_user_prompt})\n",
        "\n",
        "# Make the second API call with the updated messages\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN4kuy4vTrtf",
        "outputId": "c3b162f9-fef4-4d1c-bbdd-98ec0417f14b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physicists over the years have been in search of a \"unified theory\" which is also known as the \"Theory of Everything\" (ToE). Essentially, they are trying to unify the four fundamental forces of nature: gravity, electromagnetism, and the strong and weak nuclear forces into a single theoretical framework.\n",
            "\n",
            "Albert Einstein's general theory of relativity brilliantly explained gravity. Quantum mechanics, on the other hand, has been exceptional in explaining the behavior of the three other non-gravitational forces - electromagnetism, and the strong and weak nuclear forces.\n",
            "\n",
            "The problem, however, is reconciling general relativity, which works on a macroscopic level (planets, galaxies, etc), with quantum mechanics, which operates at the minuscule level of particles that are subatomic. They simply do not fit together. General relativity portrays space as a smooth fabric, while quantum mechanics portrays it as a jittery, fluctuating froth at extremely small scales.\n",
            "\n",
            "String theory, however, has the potential to reconcile these seemingly incompatible theories. According to string theory, at the most fundamental level, all matter and energy is made up of tiny, vibrating \"strands\" (or \"strings\") of energy, not point particles as suggested by quantum mechanics. Different vibration modes of these strings correspond to different particles, which are mediators of the fundamental forces in nature.\n",
            "\n",
            "Crucially, one of the vibrational states of a string corresponds to a graviton, a theoretical particle that would carry the force of gravity in a quantum theory of gravity. This incorporation of gravity in a quantum context is what makes string theory a strong candidate for a unified theory.\n",
            "\n",
            "However, it's also important to note that while incredibly promising and intriguing, the string theory is still unproven and in the realm of theoretical physics – it's yet to be validated through empirical experiments. This is partly due to the fact that the energies required to test string theory directly are far beyond our current capabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtSC6WmBw4wX"
      },
      "source": [
        "### Dealing with Hallucinations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAhStCG9w4wX"
      },
      "source": [
        "We have our chatbot, but as mentioned — the knowledge of LLMs can be limited. The reason for this is that LLMs learn all they know during training. An LLM essentially compresses the \"world\" as seen in the training data into the internal parameters of the model. We call this knowledge the _parametric knowledge_ of the model.\n",
        "\n",
        "By default, LLMs have no access to the external world.\n",
        "\n",
        "The result of this is very clear when we ask LLMs about more recent information, like about the new (and very popular) Llama 2 LLM."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the latest AI response to messages\n",
        "messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "# Create a new user prompt\n",
        "prompt = {\"role\": \"user\", \"content\": \"What is so special about Llama 2?\"}\n",
        "\n",
        "# Add to messages\n",
        "messages.append(prompt)\n",
        "\n",
        "# Send to OpenAI (chat-gpt equivalent)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJnocMJXVPNw",
        "outputId": "e91be13f-122f-49de-b7ae-1fee0ef916b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Llama 2\" generally refers to an antibody treatment developed for COVID-19. Allow me to explain:\n",
            "\n",
            "A group of scientists discovered that llamas produce a unique kind of antibody, called a nanobody, that can tightly bind and neutralize SARS-CoV-2, the virus responsible for COVID-19. \n",
            "\n",
            "\"Llama 2\" is the name given to one of these nanobodies. These antibodies are much smaller than human antibodies. Because they're easily manipulated and stable, these \"llama antibodies\" could be stacked to neutralize the virus more effectively which could be used as a potential treatment or prevention for COVID-19. \n",
            "\n",
            "It's important to note that although this treatment showed promise in laboratory settings, more research and trials are needed to determine if it would be an effective treatment for humans infected with the virus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YORp9R_Pw4wX"
      },
      "source": [
        "Our chatbot can no longer help us, it doesn't contain the information we need to answer the question. It was very clear from this answer that the LLM doesn't know the informaiton, but sometimes an LLM may respond like it _does_ know the answer — and this can be very hard to detect.\n",
        "\n",
        "OpenAI have since adjusted the behavior for this particular example as we can see below:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the latest AI response to messages\n",
        "messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "# Create a new user prompt\n",
        "prompt = {\"role\": \"user\", \"content\": \"Can you tell me about the LLMChain in LangChain?\"}\n",
        "\n",
        "# Add to messages\n",
        "messages.append(prompt)\n",
        "\n",
        "# Send to OpenAI (chat-gpt equivalent)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zITufhTOYFwx",
        "outputId": "8ee96826-298b-434d-fdde-9e91eca116db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry for the confusion, but it appears there is a misunderstanding. The details regarding \"LLMChain\" in \"LangChain\" are not clear since there isn't publicly available information about such terms in present databases or literature connected to technology, cryptocurrency, or linguistics. If these are related to a specific, narrowly-defined context or new technology, could you please provide more details or clarify?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma4gl6-rw4wX"
      },
      "source": [
        "There is another way of feeding knowledge into LLMs. It is called _source knowledge_ and it refers to any information fed into the LLM via the prompt. We can try that with the LLMChain question. We can take a description of this object from the LangChain documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th7n7OZaw4wX"
      },
      "source": [
        "We can feed this additional knowledge into our prompt with some instructions telling the LLM how we'd like it to use this information alongside our original query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAwwu54Ow4wX"
      },
      "source": [
        "Now we feed this into our chatbot as we were before."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LLMChain information\n",
        "llmchain_information = [\n",
        "    \"A LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format.\",\n",
        "    \"Chains is an incredibly generic concept which returns to a sequence of modular components (or other chains) combined in a particular way to accomplish a common use case.\",\n",
        "    \"LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an API, but will also: (1) Be data-aware: connect a language model to other sources of data, (2) Be agentic: Allow a language model to interact with its environment. As such, the LangChain framework is designed with the objective in mind to enable those types of applications.\"\n",
        "]\n",
        "\n",
        "# Combine the LLMChain information into a single string\n",
        "source_knowledge = \"\\n\".join(llmchain_information)\n",
        "\n",
        "# Define the query\n",
        "query = \"Can you tell me about the LLMChain in LangChain?\"\n",
        "\n",
        "# Create the augmented prompt\n",
        "augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
        "\n",
        "Contexts:\n",
        "{source_knowledge}\n",
        "\n",
        "Query: {query}\"\"\"\n",
        "\n",
        "# Create a new user prompt\n",
        "prompt = {\"role\": \"user\", \"content\": augmented_prompt}\n",
        "\n",
        "# Initialize the conversation if messages list is undefined\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
        "]\n",
        "\n",
        "# Add the new prompt to the conversation\n",
        "messages.append(prompt)\n",
        "\n",
        "# Send the messages to OpenAI\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfqGvWSNcKE6",
        "outputId": "1fec0d4a-9aec-4050-8ae0-566de63bf810"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The LLMChain in LangChain is a common type of chain that includes multiple components: a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. The function of the LLMChain is to handle multiple input variables. The Chain uses the PromptTemplate to shape these variables into a prompt that is then passed to the model. If an OutputParser is provided, it will interpret the output of the LLM, formatting it into a finalized version. In essence, the LLMChain is a key part of the LangChain framework, which aims to develop applications that utilize language models in an interactive and data-aware manner.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNdgE8hZw4wY"
      },
      "source": [
        "The quality of this answer is phenomenal. This is made possible thanks to the idea of augmented our query with external knowledge (source knowledge). There's just one problem — how do we get this information in the first place?\n",
        "\n",
        "We learned in the previous chapters about Pinecone and vector databases. Well, they can help us here too. But first, we'll need a dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sWZzcbsKewq4",
        "outputId": "a8434337-57ce-4eeb-9100-6b44bd9615af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BBR4PWnZmTYi",
        "outputId": "c3f3dfac-2f19-484c-a2d2-96e2a86ed59f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.9)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Collecting langchain<0.4.0,>=0.3.11 (from langchain-community)\n",
            "  Using cached langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.24 (from langchain-community)\n",
            "  Using cached langchain_core-0.3.24-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langsmith<0.3,>=0.1.125 (from langchain-community)\n",
            "  Using cached langsmith-0.2.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.11->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.11->langchain-community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community) (2.27.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\n",
            "Using cached langchain_community-0.3.11-py3-none-any.whl (2.5 MB)\n",
            "Using cached langchain-0.3.11-py3-none-any.whl (1.0 MB)\n",
            "Using cached langchain_core-0.3.24-py3-none-any.whl (410 kB)\n",
            "Using cached langsmith-0.2.2-py3-none-any.whl (320 kB)\n",
            "Installing collected packages: langsmith, langchain-core, langchain, langchain-community\n",
            "Successfully installed langchain-0.3.11 langchain-community-0.3.11 langchain-core-0.3.24 langsmith-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload your own custom code files to the model"
      ],
      "metadata": {
        "id": "yKdtLTWCEskG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DuFPmMhew4wY",
        "outputId": "a26082b6-3cfd-4391-8d87-e490b00398ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents loaded: 1\n",
            "Document Metadata: {'source': 'code.ipynb', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}\n",
            "Document Content: {\n",
            "  \"nbformat\": 4,\n",
            "  \"nbformat_minor\": 0,\n",
            "  \"metadata\": {\n",
            "    \"colab\": {\n",
            "      \"provenance\": []\n",
            "    },\n",
            "    \"kernelspec\": {\n",
            "      \"name\": \"python3\",\n",
            "      \"display_name\": \"Python 3\"\n",
            "    },\n",
            "    \"language_info\": {\n",
            "      \"name\": \"python\"\n",
            "    }\n",
            "  },\n",
            "  \"cells\": [\n",
            "    {\n",
            "      \"cell_type\": \"markdown\",\n",
            "      \"source\": [\n",
            "        \"## Installing libraries\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"4KUVqVe0fGxH\"\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"code\",\n",
            "      \"source\": [\n",
            "        \"!pip install request\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders.generic import GenericLoader\n",
        "from langchain_community.document_loaders.parsers import LanguageParser\n",
        "from langchain_text_splitters import Language\n",
        "import os\n",
        "\n",
        "# Define the uploaded file path (update with your file name if different)\n",
        "uploaded_file_path = \"code.ipynb\"\n",
        "\n",
        "# Loader to process the single `.ipynb` file\n",
        "loader = GenericLoader.from_filesystem(\n",
        "    uploaded_file_path,\n",
        "    glob=\"*\",\n",
        "    suffixes=[\".ipynb\"],\n",
        "    parser=LanguageParser(language=Language.PYTHON, parser_threshold=500),  # Treat as Python\n",
        ")\n",
        "\n",
        "# Load the content\n",
        "documents = loader.load()\n",
        "\n",
        "# Check the number of documents loaded\n",
        "print(f\"Number of documents loaded: {len(documents)}\")\n",
        "\n",
        "# Print document details\n",
        "for doc in documents:\n",
        "    print(\"Document Metadata:\", doc.metadata)\n",
        "    print(\"Document Content:\", doc.page_content[:500])  # Print the first 500 characters\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo2BvRkrosTA",
        "outputId": "2fbee2cf-d98f-4eea-9407-f3276e63680f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'code.ipynb', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}, page_content='{\\n  \"nbformat\": 4,\\n  \"nbformat_minor\": 0,\\n  \"metadata\": {\\n    \"colab\": {\\n      \"provenance\": []\\n    },\\n    \"kernelspec\": {\\n      \"name\": \"python3\",\\n      \"display_name\": \"Python 3\"\\n    },\\n    \"language_info\": {\\n      \"name\": \"python\"\\n    }\\n  },\\n  \"cells\": [\\n    {\\n      \"cell_type\": \"markdown\",\\n      \"source\": [\\n        \"## Installing libraries\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"4KUVqVe0fGxH\"\\n      }\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"!pip install requests bs4 PyPDF2 openai\\\\n\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"Jn_H2B_DYuKj\",\\n        \"colab\": {\\n          \"base_uri\": \"https://localhost:8080/\"\\n        },\\n        \"outputId\": \"83ccacd4-0c8c-4fb2-e549-9e91e039d5d0\"\\n      },\\n      \"execution_count\": 31,\\n      \"outputs\": [\\n        {\\n          \"output_type\": \"stream\",\\n          \"name\": \"stdout\",\\n          \"text\": [\\n            \"Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\\\\n\",\\n            \"Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.2)\\\\n\",\\n            \"Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\\\\n\",\\n            \"Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\\\\n\",\\n            \"Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\\\\n\",\\n            \"Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\\\\n\",\\n            \"Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\\\\n\",\\n            \"Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\\\\n\",\\n            \"Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\\\\n\",\\n            \"Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\\\\n\",\\n            \"Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\\\\n\",\\n            \"Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\\\\n\",\\n            \"Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\\\\n\",\\n            \"Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\\\\n\",\\n            \"Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\\\\n\",\\n            \"Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\\\\n\",\\n            \"Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\\\\n\",\\n            \"Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\\\\n\",\\n            \"Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\\\\n\",\\n            \"Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\\\\n\",\\n            \"Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\\\\n\",\\n            \"Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\\\\n\",\\n            \"Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.6)\\\\n\"\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"markdown\",\\n      \"source\": [\\n        \"#### Import libraries\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"bFY1BLNu4kIf\"\\n      }\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"import openai\\\\n\",\\n        \"import requests\\\\n\",\\n        \"from bs4 import BeautifulSoup\\\\n\",\\n        \"import PyPDF2\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"VfS0Orb-pzTI\"\\n      },\\n      \"execution_count\": 32,\\n      \"outputs\": []\\n    },\\n    {\\n      \"cell_type\": \"markdown\",\\n      \"source\": [\\n        \"#### OPENAI API keys\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"9S7osbxa4ihp\"\\n      }\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"openai.api_key = \\'your-openai-key\\'\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"GznL9wpRpzxt\"\\n      },\\n      \"execution_count\": 33,\\n      \"outputs\": []\\n    },\\n    {\\n      \"cell_type\": \"markdown\",\\n      \"source\": [\\n        \"##       a. Ask the bot to solve one complex math problem.\\\\n\",\\n        \"\\\\n\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"eZ2H7fB6ZcB0\"\\n      }\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"# Solve math problems\\\\n\",\\n        \"def complex_math_problem(problem, model=\\\\\"gpt-4\\\\\"):\\\\n\",\\n        \"    try:\\\\n\",\\n        \"        response = openai.chat.completions.create(\\\\n\",\\n        \"            model=model,\\\\n\",\\n        \"            messages=[\\\\n\",\\n        \"                {\\\\\"role\\\\\": \\\\\"system\\\\\", \\\\\"content\\\\\": \\\\\"You are an experienced math teacher.\\\\\"},\\\\n\",\\n        \"                {\\\\\"role\\\\\": \\\\\"user\\\\\", \\\\\"content\\\\\": f\\\\\"Solve the problem step-by-step:\\\\\\\\n\\\\\\\\n: {problem}\\\\\"}\\\\n\",\\n        \"            ],\\\\n\",\\n        \"            max_tokens=1000,\\\\n\",\\n        \"            temperature=0.5\\\\n\",\\n        \"        )\\\\n\",\\n        \"        return response.choices[0].message.content.strip()\\\\n\",\\n        \"    except Exception as e:\\\\n\",\\n        \"        return f\\\\\"Error occured while solving a math problem: {e}\\\\\"\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"EuX8bsZMPM1Q\"\\n      },\\n      \"execution_count\": 34,\\n      \"outputs\": []\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"# Step 1: Solve a math problem\\\\n\",\\n        \"math_problem = (\\\\n\",\\n        \"    \\'You are an experienced math teacher. Please solve the following math problem step-by-step\\'\\\\n\",\\n        \"    \\'Explain each concept and calculation in detail to ensure thorough understanding:\\\\\\\\n\\\\\\\\n\\'\\\\n\",\\n        \"  \\\\\"\\\\\"\\\\\"\\\\n\",\\n        \"    Using the financial data from Alphabet Inc.\\'s Q3 2024 SEC filing, calculate the company\\'s Weighted Average Cost of Capital (WACC). Assume the following details extracted from the report:\\\\n\",\\n        \"\\\\n\",\\n        \"      Market Value of Equity (E): $1.5 trillion\\\\n\",\\n        \"      Market Value of Debt (D): $50 billion\\\\n\",\\n        \"      Cost of Equity (Re): Calculated using the Capital Asset Pricing Model (CAPM), where the Risk-Free Rate (Rf) is 3%, the Equity Beta (β) is 1.1, and the Market Risk Premium (Rm - Rf) is 6%.\\\\n\",\\n        \"      Cost of Debt (Rd): 4%\\\\n\",\\n        \"      Corporate Tax Rate (Tc): 21%**\\\\n\",\\n        \"      Calculate Alphabet\\'s WACC and interpret its implications for the company\\'s investment decisions in .\\\\n\",\\n        \"  \\\\\"\\\\\"\\\\\"\\\\n\",\\n        \")\\\\n\",\\n        \"\\\\n\",\\n        \"math_solution = complex_math_problem(math_problem)\\\\n\",\\n        \"print(\\\\\"\\\\\\\\nMath Problem Solution:\\\\\\\\n\\\\\", math_solution)\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"jUTXjdytPMzP\",\\n        \"colab\": {\\n          \"base_uri\": \"https://localhost:8080/\"\\n        },\\n        \"outputId\": \"e46fa9a1-81fd-4635-be8d-b5526e00531d\"\\n      },\\n      \"execution_count\": 35,\\n      \"outputs\": [\\n        {\\n          \"output_type\": \"stream\",\\n          \"name\": \"stdout\",\\n          \"text\": [\\n            \"\\\\n\",\\n            \"Math Problem Solution:\\\\n\",\\n            \" The Weighted Average Cost of Capital (WACC) is a key factor in corporate finance because it is often used to determine a company\\'s cost of capital. It represents the average rate that a company is expected to pay to finance its assets. WACC is the minimum average rate of return which a company must earn on its existing asset base to satisfy its creditors, owners, and other providers of capital.\\\\n\",\\n            \"\\\\n\",\\n            \"Here is how you can calculate Alphabet Inc.\\'s WACC using the given data:\\\\n\",\\n            \"\\\\n\",\\n            \"First, we need to calculate the weights of equity and debt in the company\\'s capital structure. \\\\n\",\\n            \"\\\\n\",\\n            \"The weight of equity (We) is calculated as the Market Value of Equity divided by the total Market Value of Equity and Debt.\\\\n\",\\n            \"\\\\n\",\\n            \"We = E / (E + D)\\\\n\",\\n            \"We = $1.5 trillion / ($1.5 trillion + $50 billion)\\\\n\",\\n            \"We = 0.968 or 96.8%\\\\n\",\\n            \"\\\\n\",\\n            \"Similarly, the weight of debt (Wd) is calculated as the Market Value of Debt divided by the total Market Value of Equity and Debt.\\\\n\",\\n            \"\\\\n\",\\n            \"Wd = D / (E + D)\\\\n\",\\n            \"Wd = $50 billion / ($1.5 trillion + $50 billion)\\\\n\",\\n            \"Wd = 0.032 or 3.2%\\\\n\",\\n            \"\\\\n\",\\n            \"Next, we need to calculate the Cost of Equity (Re). It\\'s given that we should use the Capital Asset Pricing Model (CAPM) to calculate this. The CAPM formula is:\\\\n\",\\n            \"\\\\n\",\\n            \"Re = Rf + β * (Rm - Rf)\\\\n\",\\n            \"Re = 3% + 1.1 * (6%)\\\\n\",\\n            \"Re = 3% + 6.6% = 9.6%\\\\n\",\\n            \"\\\\n\",\\n            \"The Cost of Debt (Rd) is given as 4%. However, we need to adjust this for taxes as the interest expense on debt is tax-deductible. The after-tax Cost of Debt (Rd(1-Tc)) is calculated as:\\\\n\",\\n            \"\\\\n\",\\n            \"Rd(1-Tc) = Rd * (1 - Tc)\\\\n\",\\n            \"Rd(1-Tc) = 4% * (1 - 21%)\\\\n\",\\n            \"Rd(1-Tc) = 3.16%\\\\n\",\\n            \"\\\\n\",\\n            \"Now, we can calculate the WACC. The WACC formula is:\\\\n\",\\n            \"\\\\n\",\\n            \"WACC = We*Re + Wd*Rd(1-Tc)\\\\n\",\\n            \"WACC = 0.968 * 9.6% + 0.032 * 3.16%\\\\n\",\\n            \"WACC = 9.3% + 0.1%\\\\n\",\\n            \"WACC = 9.4%\\\\n\",\\n            \"\\\\n\",\\n            \"So, Alphabet Inc.\\'s WACC is 9.4%. \\\\n\",\\n            \"\\\\n\",\\n            \"This means that, on average, Alphabet Inc. needs to earn a minimum return of 9.4% from its investments to satisfy its investors and creditors. If Alphabet Inc. can earn a return higher than this, it will create value for its shareholders. If it earns less, it may be better off paying its excess cash to its shareholders so they can invest it elsewhere.\\\\n\"\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"markdown\",\\n      \"source\": [\\n        \"## b. Give a PDF and website document; ask the bot to rewrite and answer questions on the given PDF and website.\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"1auV0O_QZgks\"\\n      }\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"# Extract PDF content\\\\n\",\\n        \"def extract_pdf_text(pdf_path):\\\\n\",\\n        \"    try:\\\\n\",\\n        \"        with open(pdf_path, \\\\\"rb\\\\\") as pdf_file:\\\\n\",\\n        \"            reader = PyPDF2.PdfReader(pdf_file)\\\\n\",\\n        \"            text = \\\\\"\\\\\"\\\\n\",\\n        \"            for page in reader.pages:\\\\n\",\\n        \"                text += page.extract_text()\\\\n\",\\n        \"        return text.strip()\\\\n\",\\n        \"    except Exception as e:\\\\n\",\\n        \"        return f\\\\\"Error reading PDF: {e}\\\\\"\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"IH2tpLTWbAnC\"\\n      },\\n      \"execution_count\": 36,\\n      \"outputs\": []\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"def fetch_website_content(website_url):\\\\n\",\\n        \"    try:\\\\n\",\\n        \"        response = requests.get(website_url)\\\\n\",\\n        \"        if response.status_code == 200:\\\\n\",\\n        \"            soup = BeautifulSoup(response.content, \\\\\"html.parser\\\\\")\\\\n\",\\n        \"            paragraphs = soup.find_all(\\\\\"p\\\\\")\\\\n\",\\n        \"            content = \\\\\" \\\\\".join([para.get_text() for para in paragraphs])\\\\n\",\\n        \"            return content.strip()\\\\n\",\\n        \"        else:\\\\n\",\\n        \"            return f\\\\\"Failed to fetch website content. Status code: {response.status_code}\\\\\"\\\\n\",\\n        \"    except Exception as e:\\\\n\",\\n        \"        return f\\\\\"Error fetching website: {e}\\\\\"\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"dZt0v8Tja_CO\"\\n      },\\n      \"execution_count\": 37,\\n      \"outputs\": []\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"# Rewrite content using OpenAI\\\\n\",\\n        \"def rewrite_content(content, model=\\\\\"gpt-4\\\\\"):\\\\n\",\\n        \"    try:\\\\n\",\\n        \"        response = openai.chat.completions.create(\\\\n\",\\n        \"            model=model,\\\\n\",\\n        \"            messages=[\\\\n\",\\n        \"                {\\\\\"role\\\\\": \\\\\"system\\\\\", \\\\\"content\\\\\": \\\\\"You are a content rewriter.\\\\\"},\\\\n\",\\n        \"                {\\\\\"role\\\\\": \\\\\"user\\\\\", \\\\\"content\\\\\": f\\\\\"Rewrite these documents into a cohesive summary:\\\\\\\\n\\\\\\\\n{content}\\\\\"}\\\\n\",\\n        \"            ],\\\\n\",\\n        \"            max_tokens=1500,\\\\n\",\\n        \"            temperature=0.7\\\\n\",\\n        \"        )\\\\n\",\\n        \"        return response.choices[0].message.content.strip()\\\\n\",\\n        \"    except Exception as e:\\\\n\",\\n        \"        return f\\\\\"Error rewriting content: {e}\\\\\"\\\\n\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"v59ZdzRPbb3R\"\\n      },\\n      \"execution_count\": 38,\\n      \"outputs\": []\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"#rewrite pdf\\\\n\",\\n        \"pdf_path = \\\\\"alphabet-2024q3_report.pdf\\\\\"\\\\n\",\\n        \"pdf_content = extract_pdf_text(pdf_path)\\\\n\",\\n        \"rewritten_pdf_content = rewrite_content(pdf_content)\\\\n\",\\n        \"print(f\\\\\"Rewritten PDF Content:\\\\\\\\n\\\\\\\\n{rewritten_pdf_content}\\\\\")\"\\n      ],\\n      \"metadata\": {\\n        \"colab\": {\\n          \"base_uri\": \"https://localhost:8080/\"\\n        },\\n        \"id\": \"xdpMNFEZT5Y4\",\\n        \"outputId\": \"66e20d16-5032-4dad-b5a0-78d213545ae1\"\\n      },\\n      \"execution_count\": 39,\\n      \"outputs\": [\\n        {\\n          \"output_type\": \"stream\",\\n          \"name\": \"stdout\",\\n          \"text\": [\\n            \"Rewritten PDF Content:\\\\n\",\\n            \"\\\\n\",\\n            \"Alphabet Inc., the parent company of Google, announced its Q3 2024 financial results on October 29, 2024. The company\\'s consolidated revenues for the quarter, ended September 30, 2024, increased by 15% year over year to reach $88.3 billion. This reflects strong momentum across the business. Google Services revenues increased by 13% to $76.5 billion, driven by growth in Google Search and other products, Google subscriptions, platforms, devices, and YouTube ads. Google Cloud revenues saw a 35% increase to $11.4 billion, spurred by growth in Google Cloud Platform\\'s AI Infrastructure, Generative AI Solutions, and core GCP products. The company\\'s total operating income increased by 34%, and its operating margin percent expanded by 4.5 percentage points to 32%. Net income also increased by 34%, and earnings per share (EPS) increased by 37% to $2.12. Sundar Pichai, CEO of Alphabet, highlighted the company\\'s commitment to innovation and investment in AI, which are benefiting consumers and partners. In addition to strong revenue growth, the company\\'s efforts to improve efficiency also resulted in improved margins.\\\\n\"\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"#rewrite website\\\\n\",\\n        \"website_url = \\\\\"https://blog.google/inside-google/message-ceo/alphabet-earnings-q3-2024/\\\\\"\\\\n\",\\n        \"\\\\n\",\\n        \"web_content = fetch_website_content(website_url)\\\\n\",\\n        \"rewritten_web_content = rewrite_content(web_content)\\\\n\",\\n        \"\\\\n\",\\n        \"print(f\\\\\"Rewritten Website Content:\\\\\\\\n\\\\\\\\n{rewritten_web_content}\\\\\")\\\\n\"\\n      ],\\n      \"metadata\": {\\n        \"colab\": {\\n          \"base_uri\": \"https://localhost:8080/\"\\n        },\\n        \"id\": \"ohejHikPUrTS\",\\n        \"outputId\": \"9ef3c402-3f15-4cee-af53-69f49251b759\"\\n      },\\n      \"execution_count\": 40,\\n      \"outputs\": [\\n        {\\n          \"output_type\": \"stream\",\\n          \"name\": \"stdout\",\\n          \"text\": [\\n            \"Rewritten Website Content:\\\\n\",\\n            \"\\\\n\",\\n            \"Google and Alphabet CEO, Sundar Pichai, recently reported their exceptional Q3 results in 2024, attributing the success to strong performance in Search, Cloud, and YouTube sectors. The company\\'s momentum and innovative initiatives, particularly in the area of Artificial Intelligence (AI), have been key drivers of success. \\\\n\",\\n            \"\\\\n\",\\n            \"The company\\'s approach to AI innovation involves a three-pronged model: infrastructure investment, research, and customer experience. Google continues to invest in advanced infrastructure, from the U.S. to Thailand to Uruguay, including clean energy initiatives and efficiency improvements in data centers. They\\'ve also reduced costs significantly through hardware, engineering, and technical breakthroughs, while doubling the size of their custom Gemini model.\\\\n\",\\n            \"\\\\n\",\\n            \"Research-wise, Google\\'s DeepMind team, led by Nobel laureates Demis Hassabis and John Jumper, is pioneering AI advancements. They\\'ve also seen significant growth in the usage of their Gemini models across all their products and platforms, serving over 2 billion monthly users.\\\\n\",\\n            \"\\\\n\",\\n            \"In terms of customer experience, Google has been successful in deploying AI advances to benefit its consumers, with products like Google Maps and AI Overviews enhancing the user experience. They\\'ve also made their Gemini model available to developers via GitHub Copilot. \\\\n\",\\n            \"\\\\n\",\\n            \"The company has organized itself to operate with speed and agility, and they are using AI internally to improve coding processes, boosting productivity and efficiency. Over a quarter of all new code at Google is now generated by AI.\\\\n\",\\n            \"\\\\n\",\\n            \"In terms of individual sectors, Google Search has been transformed by AI advancements, leading to increased search queries and user satisfaction. Google Cloud generated Q3 revenues of $11.4 billion, a 35% increase from last year, driven by their AI portfolio and technology leadership. YouTube\\'s combined ad and subscription revenue surpassed $50 billion for the first time ever, driven by YouTube TV, NFL Sunday Ticket, and YouTube Music Premium.\\\\n\",\\n            \"\\\\n\",\\n            \"Google\\'s Other Bets, particularly Waymo, the autonomous vehicle industry leader, has been integrating cutting-edge AI into its work, driving more than 1 million fully autonomous miles per week and serving over 150,000 paid rides. \\\\n\",\\n            \"\\\\n\",\\n            \"In closing, Pichai welcomed their new CFO, Anat, and expressed gratitude to their global employees for their hard work and dedication. He also paid tribute to Susan Wojcicki, a former YouTube CEO who recently passed away from lung cancer.\\\\n\"\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"# Answer questions based on rewritten content\\\\n\",\\n        \"def answer_question(content, question, model=\\\\\"gpt-4\\\\\"):\\\\n\",\\n        \"    try:\\\\n\",\\n        \"        response = openai.chat.completions.create(\\\\n\",\\n        \"            model=model,\\\\n\",\\n        \"            messages=[\\\\n\",\\n        \"                {\\\\\"role\\\\\": \\\\\"system\\\\\", \\\\\"content\\\\\": \\\\\"You are an assistant that answers questions based on provided content.\\\\\"},\\\\n\",\\n        \"                {\\\\\"role\\\\\": \\\\\"user\\\\\", \\\\\"content\\\\\": f\\\\\"Content:\\\\\\\\n{content}\\\\\\\\n\\\\\\\\nQuestion: {question}\\\\\"}\\\\n\",\\n        \"            ],\\\\n\",\\n        \"            max_tokens=500,\\\\n\",\\n        \"            temperature=0.5\\\\n\",\\n        \"        )\\\\n\",\\n        \"        return response.choices[0].message.content.strip()\\\\n\",\\n        \"    except Exception as e:\\\\n\",\\n        \"        return f\\\\\"Error answering question: {e}\\\\\"\\\\n\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"JMQtnPFKY51W\"\\n      },\\n      \"execution_count\": 41,\\n      \"outputs\": []\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"# Example questions for the rewritten content\\\\n\",\\n        \"pdf_question = \\\\\"What were Alphabet Inc.\\'s key financial highlights from Q3 2024?\\\\\"\\\\n\",\\n        \"web_question = \\\\\"What were the main announcements made by Alphabet\\'s CEO in the Q3 earnings blog post?\\\\\"\\\\n\",\\n        \"\\\\n\",\\n        \"# Answer questions based on the rewritten PDF content\\\\n\",\\n        \"pdf_answer = answer_question(rewritten_pdf_content, pdf_question)\\\\n\",\\n        \"print(\\\\\"\\\\\\\\nAnswer to PDF Question:\\\\\\\\n\\\\\", pdf_answer)\\\\n\",\\n        \"\\\\n\",\\n        \"# Answer questions based on the rewritten website content\\\\n\",\\n        \"web_answer = answer_question(rewritten_web_content, web_question)\\\\n\",\\n        \"print(\\\\\"\\\\\\\\nAnswer to Website Question:\\\\\\\\n\\\\\", web_answer)\\\\n\"\\n      ],\\n      \"metadata\": {\\n        \"colab\": {\\n          \"base_uri\": \"https://localhost:8080/\"\\n        },\\n        \"id\": \"elCgGhvvY9GZ\",\\n        \"outputId\": \"4881ea63-a3f6-4822-c98a-703f287d21cf\"\\n      },\\n      \"execution_count\": 42,\\n      \"outputs\": [\\n        {\\n          \"output_type\": \"stream\",\\n          \"name\": \"stdout\",\\n          \"text\": [\\n            \"\\\\n\",\\n            \"Answer to PDF Question:\\\\n\",\\n            \" Alphabet Inc.\\'s key financial highlights from Q3 2024 include:\\\\n\",\\n            \"1. Consolidated revenues increased by 15% year over year to reach $88.3 billion.\\\\n\",\\n            \"2. Google Services revenues increased by 13% to $76.5 billion, driven by growth in Google Search and other products, Google subscriptions, platforms, devices, and YouTube ads.\\\\n\",\\n            \"3. Google Cloud revenues saw a 35% increase to $11.4 billion, spurred by growth in Google Cloud Platform\\'s AI Infrastructure, Generative AI Solutions, and core GCP products.\\\\n\",\\n            \"4. The company\\'s total operating income increased by 34%, and its operating margin percent expanded by 4.5 percentage points to 32%.\\\\n\",\\n            \"5. Net income also increased by 34%, and earnings per share (EPS) increased by 37% to $2.12.\\\\n\",\\n            \"6. The company\\'s commitment to innovation and investment in AI was highlighted, which has benefited consumers and partners.\\\\n\",\\n            \"7. In addition to strong revenue growth, the company\\'s efforts to improve efficiency also resulted in improved margins.\\\\n\",\\n            \"\\\\n\",\\n            \"Answer to Website Question:\\\\n\",\\n            \" The main announcements made by Alphabet\\'s CEO, Sundar Pichai, in the Q3 earnings blog post were:\\\\n\",\\n            \"\\\\n\",\\n            \"1. Google and Alphabet had exceptional Q3 results in 2024, attributed to strong performance in Search, Cloud, and YouTube sectors.\\\\n\",\\n            \"2. The company\\'s momentum and innovative initiatives, particularly in Artificial Intelligence (AI), were key drivers of success.\\\\n\",\\n            \"3. Google\\'s approach to AI innovation involves a three-pronged model: infrastructure investment, research, and customer experience.\\\\n\",\\n            \"4. Google has been investing in advanced infrastructure globally, reducing costs significantly, and doubling the size of their custom Gemini model.\\\\n\",\\n            \"5. In terms of research, Google\\'s DeepMind team, led by Demis Hassabis and John Jumper, is pioneering AI advancements.\\\\n\",\\n            \"6. Google has been successful in deploying AI advances to benefit its consumers, with products like Google Maps and AI Overviews. They\\'ve also made their Gemini model available to developers.\\\\n\",\\n            \"7. Google is using AI internally to improve coding processes, with over a quarter of all new code at Google now generated by AI.\\\\n\",\\n            \"8. Google Search, Google Cloud, and YouTube have seen significant growth, with Google Cloud generating Q3 revenues of $11.4 billion and YouTube\\'s combined ad and subscription revenue surpassing $50 billion.\\\\n\",\\n            \"9. Waymo, part of Google\\'s Other Bets, has been integrating AI into its work, driving more than 1 million fully autonomous miles per week and serving over 150,000 paid rides.\\\\n\",\\n            \"10. Pichai welcomed their new CFO, Anat, and expressed gratitude to their global employees. He also paid tribute to Susan Wojcicki, a former YouTube CEO who recently passed away.\\\\n\"\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"markdown\",\\n      \"source\": [\\n        \"##      c. At the end, ask the bot to summarize your chat.\\\\n\",\\n        \"\\\\n\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"fbLwNXFsZj0M\"\\n      }\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"# Summarize the conversation\\\\n\",\\n        \"def chat_summarization(messages, model=\\\\\"gpt-4\\\\\"):\\\\n\",\\n        \"    try:\\\\n\",\\n        \"        chat_content = \\\\\"\\\\\\\\n\\\\\".join(messages)\\\\n\",\\n        \"        response = openai.chat.completions.create(\\\\n\",\\n        \"            model=model,\\\\n\",\\n        \"            messages=[\\\\n\",\\n        \"                {\\\\\"role\\\\\": \\\\\"system\\\\\", \\\\\"content\\\\\": \\\\\"You are a summarization assistant.\\\\\"},\\\\n\",\\n        \"                {\\\\\"role\\\\\": \\\\\"user\\\\\", \\\\\"content\\\\\": f\\\\\"Summarize this chat session:\\\\\\\\n\\\\\\\\n{chat_content}\\\\\"}\\\\n\",\\n        \"            ],\\\\n\",\\n        \"            max_tokens=300,\\\\n\",\\n        \"            temperature=0.5\\\\n\",\\n        \"        )\\\\n\",\\n        \"        return response.choices[0].message.content.strip()\\\\n\",\\n        \"    except Exception as e:\\\\n\",\\n        \"        return f\\\\\"Error summarizing chat: {e}\\\\\"\"\\n      ],\\n      \"metadata\": {\\n        \"id\": \"6HzHQIvMbe_g\"\\n      },\\n      \"execution_count\": 43,\\n      \"outputs\": []\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"# Step 4: Summarize the conversation\\\\n\",\\n        \"messages = [\\\\n\",\\n        \"    f\\\\\"Math Problem: {math_solution}\\\\\",\\\\n\",\\n        \"    f\\\\\"Rewritten PDF Content: {rewritten_pdf_content}\\\\\",\\\\n\",\\n        \"    f\\\\\"Rewritten Website Content: {rewritten_web_content}\\\\\"\\\\n\",\\n        \"]\\\\n\",\\n        \"summary = chat_summarization(messages)\\\\n\",\\n        \"print(\\\\\"\\\\\\\\nChat Summary:\\\\\\\\n\\\\\", summary)\\\\n\"\\n      ],\\n      \"metadata\": {\\n        \"colab\": {\\n          \"base_uri\": \"https://localhost:8080/\"\\n        },\\n        \"id\": \"xv7ktaQeVt65\",\\n        \"outputId\": \"c16f8385-d40e-4e18-ac3d-1df1aba6f5f9\"\\n      },\\n      \"execution_count\": 44,\\n      \"outputs\": [\\n        {\\n          \"output_type\": \"stream\",\\n          \"name\": \"stdout\",\\n          \"text\": [\\n            \"\\\\n\",\\n            \"Chat Summary:\\\\n\",\\n            \" The Weighted Average Cost of Capital (WACC) represents the average rate a company is expected to pay to finance its assets. In this chat session, a calculation of Alphabet Inc.\\'s WACC is done, resulting in 9.4%. This indicates that Alphabet Inc. needs to earn a minimum return of 9.4% from its investments to satisfy its investors and creditors. \\\\n\",\\n            \"\\\\n\",\\n            \"Alphabet Inc. announced its Q3 2024 financial results, showing a 15% increase in consolidated revenues to $88.3 billion. The growth was driven by Google Services, Google Cloud, and YouTube ads. The company\\'s operating income, net income, and earnings per share also increased significantly. \\\\n\",\\n            \"\\\\n\",\\n            \"CEO Sundar Pichai attributed the company\\'s success to their innovative initiatives in Artificial Intelligence (AI). The company\\'s AI approach involves infrastructure investment, research, and customer experience. They\\'ve seen growth in their Gemini models usage, and over a quarter of all new code at Google is now generated by AI. Google Search, Google Cloud, and YouTube sectors have significantly benefited from AI advancements. The company also acknowledged the contributions of their global employees and paid tribute to the late Susan Wojcicki, a former YouTube CEO.\\\\n\"\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [],\\n      \"metadata\": {\\n        \"id\": \"qYbteZ9AXV2O\"\\n      },\\n      \"execution_count\": 44,\\n      \"outputs\": []\\n    }\\n  ]\\n}')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# split text data into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=20)\n",
        "text_chunks = text_splitter.split_documents(documents)\n",
        "print(len(text_chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcZopmhPpOda",
        "outputId": "69c7f201-e9d0-4172-ff03-906be549895f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc7BdqJXpZOR",
        "outputId": "2d51f5e1-85c6-41c1-eb4b-82db318adbe6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'code.ipynb', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}, page_content='\"Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\\\\n\",\\n            \"Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\\\\n\",\\n            \"Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\\\\n\",\\n            \"Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\\\\n\",\\n            \"Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\\\\n\",\\n            \"Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\\\\n\",\\n            \"Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\\\\n\",')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reformat chunks to improve vectorization; match 'jamescalam/llama-2-arxiv-papers-chunked' format sourced from Llama 2 ArXiv papers on huggingface\n",
        "dataset = []\n",
        "\n",
        "for i, chunk in enumerate(text_chunks):\n",
        "    dataset.append({\n",
        "        'doi': '',  # you can add a DOI here if available\n",
        "        'chunk-id': str(i),\n",
        "        'chunk': chunk,\n",
        "        'id': '',  # you can add an ID here if available\n",
        "        'title': '',  # you can add a title here if available\n",
        "        'summary': '',  # you can add a summary here if available\n",
        "        'source': '',  # you can add a source here if available\n",
        "        'authors': [],  # you can add authors here if available\n",
        "        'categories': [],  # you can add categories here if available\n",
        "        'comment': '',  # you can add a comment here if available\n",
        "        'journal_ref': None,  # you can add a journal reference here if available\n",
        "        'primary_category': '',  # you can add a primary category here if available\n",
        "        'published': '',  # you can add a published date here if available\n",
        "        'updated': '',  # you can add an updated date here if available\n",
        "        'references': []  # you can add references here if available\n",
        "    })\n",
        "\n",
        "print(dataset[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0shKmUePpq0R",
        "outputId": "d352b52c-b028-47ea-9541-dc959ec4a968"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'doi': '', 'chunk-id': '3', 'chunk': Document(metadata={'source': 'code.ipynb', 'content_type': 'simplified_code', 'language': <Language.PYTHON: 'python'>}, page_content='\"Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\\\\n\",\\n            \"Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\\\\n\",\\n            \"Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\\\\n\",\\n            \"Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\\\\n\",\\n            \"Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\\\\n\",\\n            \"Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\\\\n\",'), 'id': '', 'title': '', 'summary': '', 'source': '', 'authors': [], 'categories': [], 'comment': '', 'journal_ref': None, 'primary_category': '', 'published': '', 'updated': '', 'references': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq3-dxkGw4wY"
      },
      "source": [
        "### Task 4: Building the Knowledge Base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsYU27hBw4wY"
      },
      "source": [
        "We now have a dataset that can serve as our chatbot knowledge base. Our next task is to transform that dataset into the knowledge base that our chatbot can use. To do this we must use an embedding model and vector database.\n",
        "\n",
        "We begin by initializing our connection to Pinecone, this requires a [free API key](https://app.pinecone.io)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVMoYaxpgjq7",
        "outputId": "f1b4a64d-7b86-4679-81ec-2ac412352878"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (5.0.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.8.30)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GxIvcXXOw4wb"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
        "api_key = \"your-pinecone-code\"\n",
        "\n",
        "# configure client\n",
        "pc = Pinecone(api_key=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcal_JEgw4wb"
      },
      "source": [
        "Now we setup our index specification, this allows us to define the cloud provider and region where we want to deploy our index. You can find a list of all [available providers and regions here](https://docs.pinecone.io/docs/projects)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uTLMWZPAw4wb"
      },
      "outputs": [],
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "spec = ServerlessSpec(\n",
        "    cloud=\"aws\", region=\"us-east-1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSxNjSjLw4wb"
      },
      "source": [
        "Then we initialize the index. We will be using OpenAI's `text-embedding-ada-002` model for creating the embeddings, so we set the `dimension` to `1536`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ULRvhj4aw4wb",
        "outputId": "6e50b2b8-d8be-4a3d-d014-7f4b4c75872c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "index_name = 'llama-2-rag'\n",
        "existing_indexes = [\n",
        "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
        "]\n",
        "\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in existing_indexes:\n",
        "    # if does not exist, create index\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=1536,  # dimensionality of ada 002\n",
        "        metric='dotproduct',\n",
        "        spec=spec\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    while not pc.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1)\n",
        "\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "time.sleep(1)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jae7TDz5w4wb"
      },
      "source": [
        "Our index is now ready but it's empty. It is a vector index, so it needs vectors. As mentioned, to create these vector embeddings we will OpenAI's `text-embedding-ada-002` model — we can access it via LangChain like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uCQ-XA0Vw4wb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f17d291-b109-4764-e353-cf348643b21b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-09aa59ef6670>:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embed_model = OpenAIEmbeddings(\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embed_model = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONTjqjWww4wb"
      },
      "source": [
        "Using this model we can create embeddings like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ugECVXqDw4wb",
        "outputId": "b80ab9b4-c85a-4ef5-bb4c-56bf3351534a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 1536\n"
          ]
        }
      ],
      "source": [
        "texts = [\n",
        "    'this is the first chunk of text',\n",
        "    'then another second chunk of text is here'\n",
        "]\n",
        "\n",
        "res = embed_model.embed_documents(texts)\n",
        "print(len(res), len(res[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f82zGPmIw4wb"
      },
      "source": [
        "From this we get two (aligning to our two chunks of text) 1536-dimensional embeddings.\n",
        "\n",
        "We're now ready to embed and index all our our data! We do this by looping through our dataset and embedding and inserting everything in batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "AtgH_iMuw4wb",
        "outputId": "bba262fc-d6c0-4939-982f-b7f5c8441c88",
        "colab": {
          "referenced_widgets": [
            "f993689b627a4dba87743d58bbda0542",
            "68a7cf9540bc4969ae3c948c3dc75153",
            "2d9f3a7cfd424fcf8e06e07af2eca98d",
            "ec07628cb7d44adeaca00d84247b8512",
            "8a2e0cea72c24fe0ace2c23f3ce45a53",
            "b87a19fa81fc467288bac4f630cfdffd",
            "f5366b5dbea14fb19e09bfbcd7558eb8",
            "8253fb3db2394287b3e27fcef768bd4a",
            "38bf9d42b6f64c8db57882aaa7781989",
            "5c157c06083b475b8cf6c2eaa5ae6e47",
            "9c62664309b544dda1a65087bd37d9e4"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f993689b627a4dba87743d58bbda0542"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tqdm.auto import tqdm  # for progress bar\n",
        "\n",
        "data = pd.DataFrame(dataset) # this makes it easier to iterate over the dataset\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "for i in tqdm(range(0, len(data), batch_size)):\n",
        "    i_end = min(len(data), i+batch_size)\n",
        "    # get batch of data\n",
        "    batch = data.iloc[i:i_end]\n",
        "    # generate unique ids for each chunk\n",
        "    ids = [f\"{x['doi']}-{x['chunk-id']}\" for i, x in batch.iterrows()]\n",
        "    # get text to embed\n",
        "    texts = [str(x['chunk']) for _, x in batch.iterrows()]\n",
        "\n",
        "    # embed text\n",
        "    embeds = embed_model.embed_documents(texts)\n",
        "    # get metadata to store in Pinecone\n",
        "    metadata = [\n",
        "        {'text': x['chunk'].page_content,\n",
        "         'source': x['source'],\n",
        "         'title': x['title']} for i, x in batch.iterrows()\n",
        "    ]\n",
        "    # add to Pinecone\n",
        "    index.upsert(vectors=zip(ids, embeds, metadata))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9p8OBkyw4wc"
      },
      "source": [
        "We can check that the vector index has been populated using `describe_index_stats` like before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "I3QdqBijw4wc",
        "outputId": "d50108ee-1b46-4aa6-db9d-daa1099431e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqqVoZnkw4wc"
      },
      "source": [
        "#### Retrieval Augmented Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcm-dCPCw4wc"
      },
      "source": [
        "We've built a fully-fledged knowledge base. Now it's time to connect that knowledge base to our chatbot. To do that we'll be diving back into LangChain and reusing our template prompt from earlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJPGGyXSw4wc"
      },
      "source": [
        "To use LangChain here we need to load the LangChain abstraction for a vector index, called a `vectorstore`. We pass in our vector `index` to initialize the object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4MPMJmtCw4wc",
        "outputId": "ea6c5eef-4a41-4ae1-d17c-67b2541eb45e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-8a52707b045d>:6: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.18 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-pinecone package and should be used instead. To use it run `pip install -U :class:`~langchain-pinecone` and import as `from :class:`~langchain_pinecone import Pinecone``.\n",
            "  vectorstore = Pinecone(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "text_field = \"text\"  # the metadata field that contains our text\n",
        "\n",
        "# initialize the vector store object\n",
        "vectorstore = Pinecone(\n",
        "    index, embed_model.embed_query, text_field\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zrlwGYUw4wc"
      },
      "source": [
        "Using this `vectorstore` we can already query the index and see if we have any relevant information given our question about Llama 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "oyShvreew4wc",
        "outputId": "45422af0-3bf5-43d3-aabe-c5a7e47893e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '', 'title': ''}, page_content='\"\\\\n\",\\n            \"CEO Sundar Pichai attributed the company\\'s success to their innovative initiatives in Artificial Intelligence (AI). The company\\'s AI approach involves infrastructure investment, research, and customer experience. They\\'ve seen growth in their Gemini models usage, and over a quarter of all new code at Google is now generated by AI. Google Search, Google Cloud, and YouTube sectors have significantly benefited from AI advancements. The company also acknowledged the contributions of their global employees and paid tribute to the late Susan Wojcicki, a former YouTube CEO.\\\\n\"\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [],\\n      \"metadata\": {\\n        \"id\": \"qYbteZ9AXV2O\"\\n      },\\n      \"execution_count\": 44,\\n      \"outputs\": []\\n    }\\n  ]\\n}'),\n",
              " Document(metadata={'source': '', 'title': ''}, page_content='\"\\\\n\",\\n            \"Research-wise, Google\\'s DeepMind team, led by Nobel laureates Demis Hassabis and John Jumper, is pioneering AI advancements. They\\'ve also seen significant growth in the usage of their Gemini models across all their products and platforms, serving over 2 billion monthly users.\\\\n\",\\n            \"\\\\n\",\\n            \"In terms of customer experience, Google has been successful in deploying AI advances to benefit its consumers, with products like Google Maps and AI Overviews enhancing the user experience. They\\'ve also made their Gemini model available to developers via GitHub Copilot. \\\\n\",\\n            \"\\\\n\",\\n            \"The company has organized itself to operate with speed and agility, and they are using AI internally to improve coding processes, boosting productivity and efficiency. Over a quarter of all new code at Google is now generated by AI.\\\\n\",\\n            \"\\\\n\",'),\n",
              " Document(metadata={'source': '', 'title': ''}, page_content=']\\n        }\\n      ]\\n    },\\n    {\\n      \"cell_type\": \"code\",\\n      \"source\": [\\n        \"#rewrite website\\\\n\",\\n        \"website_url = \\\\\"https://blog.google/inside-google/message-ceo/alphabet-earnings-q3-2024/\\\\\"\\\\n\",\\n        \"\\\\n\",\\n        \"web_content = fetch_website_content(website_url)\\\\n\",\\n        \"rewritten_web_content = rewrite_content(web_content)\\\\n\",\\n        \"\\\\n\",\\n        \"print(f\\\\\"Rewritten Website Content:\\\\\\\\n\\\\\\\\n{rewritten_web_content}\\\\\")\\\\n\"\\n      ],\\n      \"metadata\": {\\n        \"colab\": {\\n          \"base_uri\": \"https://localhost:8080/\"\\n        },\\n        \"id\": \"ohejHikPUrTS\",\\n        \"outputId\": \"9ef3c402-3f15-4cee-af53-69f49251b759\"\\n      },\\n      \"execution_count\": 40,\\n      \"outputs\": [\\n        {\\n          \"output_type\": \"stream\",\\n          \"name\": \"stdout\",\\n          \"text\": [\\n            \"Rewritten Website Content:\\\\n\",\\n            \"\\\\n\",')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "query = \"which language is used in code?\"\n",
        "\n",
        "vectorstore.similarity_search(query, k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huzLImnKw4wc"
      },
      "source": [
        "We return a lot of text here and it's not that clear what we need or what is relevant. Fortunately, our LLM will be able to parse this information much faster than us. All we need is to connect the output from our `vectorstore` to our `chat` chatbot. To do that we can use the same logic as we used earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Rp5NBaqfw4wc"
      },
      "outputs": [],
      "source": [
        "def augment_prompt(query: str):\n",
        "    # get top 3 results from knowledge base\n",
        "    results = vectorstore.similarity_search(query, k=3)\n",
        "    # get the text from the results\n",
        "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
        "    # feed into an augmented prompt\n",
        "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
        "\n",
        "    Contexts:\n",
        "    {source_knowledge}\n",
        "\n",
        "    Query: {query}\"\"\"\n",
        "    return augmented_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2-7QCTew4wc"
      },
      "source": [
        "Using this we produce an augmented prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Mftcb16Cw4wc",
        "outputId": "7519c733-82d6-4016-e891-104f118d6516",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the contexts below, answer the query.\n",
            "\n",
            "    Contexts:\n",
            "    \"\\n\",\n",
            "            \"CEO Sundar Pichai attributed the company's success to their innovative initiatives in Artificial Intelligence (AI). The company's AI approach involves infrastructure investment, research, and customer experience. They've seen growth in their Gemini models usage, and over a quarter of all new code at Google is now generated by AI. Google Search, Google Cloud, and YouTube sectors have significantly benefited from AI advancements. The company also acknowledged the contributions of their global employees and paid tribute to the late Susan Wojcicki, a former YouTube CEO.\\n\"\n",
            "          ]\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"code\",\n",
            "      \"source\": [],\n",
            "      \"metadata\": {\n",
            "        \"id\": \"qYbteZ9AXV2O\"\n",
            "      },\n",
            "      \"execution_count\": 44,\n",
            "      \"outputs\": []\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\"\\n\",\n",
            "            \"Research-wise, Google's DeepMind team, led by Nobel laureates Demis Hassabis and John Jumper, is pioneering AI advancements. They've also seen significant growth in the usage of their Gemini models across all their products and platforms, serving over 2 billion monthly users.\\n\",\n",
            "            \"\\n\",\n",
            "            \"In terms of customer experience, Google has been successful in deploying AI advances to benefit its consumers, with products like Google Maps and AI Overviews enhancing the user experience. They've also made their Gemini model available to developers via GitHub Copilot. \\n\",\n",
            "            \"\\n\",\n",
            "            \"The company has organized itself to operate with speed and agility, and they are using AI internally to improve coding processes, boosting productivity and efficiency. Over a quarter of all new code at Google is now generated by AI.\\n\",\n",
            "            \"\\n\",\n",
            "]\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"cell_type\": \"code\",\n",
            "      \"source\": [\n",
            "        \"#rewrite website\\n\",\n",
            "        \"website_url = \\\"https://blog.google/inside-google/message-ceo/alphabet-earnings-q3-2024/\\\"\\n\",\n",
            "        \"\\n\",\n",
            "        \"web_content = fetch_website_content(website_url)\\n\",\n",
            "        \"rewritten_web_content = rewrite_content(web_content)\\n\",\n",
            "        \"\\n\",\n",
            "        \"print(f\\\"Rewritten Website Content:\\\\n\\\\n{rewritten_web_content}\\\")\\n\"\n",
            "      ],\n",
            "      \"metadata\": {\n",
            "        \"colab\": {\n",
            "          \"base_uri\": \"https://localhost:8080/\"\n",
            "        },\n",
            "        \"id\": \"ohejHikPUrTS\",\n",
            "        \"outputId\": \"9ef3c402-3f15-4cee-af53-69f49251b759\"\n",
            "      },\n",
            "      \"execution_count\": 40,\n",
            "      \"outputs\": [\n",
            "        {\n",
            "          \"output_type\": \"stream\",\n",
            "          \"name\": \"stdout\",\n",
            "          \"text\": [\n",
            "            \"Rewritten Website Content:\\n\",\n",
            "            \"\\n\",\n",
            "\n",
            "    Query: which language is used in code?\n"
          ]
        }
      ],
      "source": [
        "print(augment_prompt(query))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZI3-CdZw4wc"
      },
      "source": [
        "There is still a lot of text here, so let's pass it onto our chat model to see how it performs."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ask questions based on the code file as context."
      ],
      "metadata": {
        "id": "chswlbn0EmYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yQajKTRlEmWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new user prompt\n",
        "prompt = {\"role\": \"user\", \"content\": augment_prompt(query)}\n",
        "\n",
        "# Add to messages\n",
        "messages.append(prompt)\n",
        "\n",
        "# Send to OpenAI (chat-gpt equivalent)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBCtB8vnBXhi",
        "outputId": "5be0b800-1d85-402c-8162-ee66cfa19d51"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The language used in the code, according to the context, is Python.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new user prompt\n",
        "prompt = {\"role\": \"user\", \"content\": \"which model is used in the code?\"}\n",
        "\n",
        "# Add to messages\n",
        "messages.append(prompt)\n",
        "\n",
        "# Send to OpenAI (chat-gpt equivalent)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Puz0Ux0mCLWW",
        "outputId": "35eab1c9-7ad6-4644-e4c0-c141e769594e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model used in the provided code is \"gpt-4\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "pBuJCW1ew4wc",
        "outputId": "a09bf32e-b8c1-4bc3-b1dd-bcc1e19e4b56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided code in the context is primarily about extracting content from a website, rephrasing it, and displaying the rephrased content. It uses the Python language and has several imported libraries such as OpenAI, requests, BeautifulSoup, and PyPDF2. \n",
            "\n",
            "Here is a brief description of the operations performed:\n",
            "\n",
            "1. The code first defines the 'fetch_website_content' function, which fetches and returns the content from a given website. It uses the 'requests' library to make a HTTP request to the website's URL, and BeautifulSoup to parse the HTML content of the website. \n",
            "\n",
            "2. Then, it defines the 'rewrite_content' function that uses the OpenAI language model (specified by a model name) to paraphrase or rewrite the fetched content. To accomplish this, it uses the OpenAI API.\n",
            "\n",
            "Finally, these functions are utilized to fetch the content from a website (specified by the 'website_url' variable), rewrite it, and print the rewritten text. \n",
            "\n",
            "Note: The actual API Keys and specific website URLs have been left out in the provided context, hence they would need to be provided for the code to run properly.\n"
          ]
        }
      ],
      "source": [
        "# Create a new user prompt\n",
        "prompt = {\"role\": \"user\", \"content\": \"Tell me a brief of the code written\"}\n",
        "\n",
        "# Add to messages\n",
        "messages.append(prompt)\n",
        "\n",
        "# Send to OpenAI (chat-gpt equivalent)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(response.choices[0].message.content.strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new user prompt\n",
        "prompt = {\"role\": \"user\", \"content\": \"What libraries are imported?\"}\n",
        "\n",
        "# Add to messages\n",
        "messages.append(prompt)\n",
        "\n",
        "# Send to OpenAI (chat-gpt equivalent)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AAuAQRdDb1a",
        "outputId": "3a94bda1-cc76-4b9b-e8bd-25143ef00895"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The libraries that are imported in the code are openai, requests, BeautifulSoup from bs4, and PyPDF2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ts3kGD0w4wc"
      },
      "source": [
        "The chatbot is able to respond about Llama 2 thanks to it's conversational history stored in `messages`. However, it doesn't know anything about the safety measures themselves as we have not provided it with that information via the RAG pipeline. Let's try again but with RAG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "cuWbaJAIw4wc",
        "outputId": "c3d6fc7a-28c8-491a-bbd8-17cf0e5c07f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The roles that are used to specify the type of input in a conversation are \"system\" and \"user\". The \"system\" role is typically used to set the behavior of the language model, while the \"user\" role provides the instruction that the model should complete.\n"
          ]
        }
      ],
      "source": [
        "# Create a new user prompt\n",
        "prompt = {\"role\": \"user\", \"content\": \"What roles are used to specify the type of input in a conversation?\"}\n",
        "\n",
        "# Add to messages\n",
        "messages.append(prompt)\n",
        "\n",
        "# Send to OpenAI (chat-gpt equivalent)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(response.choices[0].message.content.strip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPrsKLj7w4wc"
      },
      "source": [
        "Delete the index to save resources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "E8LSIHSGw4wc"
      },
      "outputs": [],
      "source": [
        "pc.delete_index(index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtiAQmWdw4wd"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f993689b627a4dba87743d58bbda0542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68a7cf9540bc4969ae3c948c3dc75153",
              "IPY_MODEL_2d9f3a7cfd424fcf8e06e07af2eca98d",
              "IPY_MODEL_ec07628cb7d44adeaca00d84247b8512"
            ],
            "layout": "IPY_MODEL_8a2e0cea72c24fe0ace2c23f3ce45a53"
          }
        },
        "68a7cf9540bc4969ae3c948c3dc75153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b87a19fa81fc467288bac4f630cfdffd",
            "placeholder": "​",
            "style": "IPY_MODEL_f5366b5dbea14fb19e09bfbcd7558eb8",
            "value": "100%"
          }
        },
        "2d9f3a7cfd424fcf8e06e07af2eca98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8253fb3db2394287b3e27fcef768bd4a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38bf9d42b6f64c8db57882aaa7781989",
            "value": 1
          }
        },
        "ec07628cb7d44adeaca00d84247b8512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c157c06083b475b8cf6c2eaa5ae6e47",
            "placeholder": "​",
            "style": "IPY_MODEL_9c62664309b544dda1a65087bd37d9e4",
            "value": " 1/1 [00:02&lt;00:00,  2.47s/it]"
          }
        },
        "8a2e0cea72c24fe0ace2c23f3ce45a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b87a19fa81fc467288bac4f630cfdffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5366b5dbea14fb19e09bfbcd7558eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8253fb3db2394287b3e27fcef768bd4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38bf9d42b6f64c8db57882aaa7781989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c157c06083b475b8cf6c2eaa5ae6e47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c62664309b544dda1a65087bd37d9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}